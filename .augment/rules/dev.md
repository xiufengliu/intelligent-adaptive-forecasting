---
type: "manual"
---

## ğŸ—ï¸ **Generic Development Rules**

### **1. Data Integrity**

* **Always use real data** â€“ No synthetic or fabricated datasets
* **Avoid academic misconduct** â€“ Never fabricate results or manipulate data
* **Use legitimate sources** â€“ Only use established benchmark datasets and real experimental data
* **Maintain data provenance** â€“ Document data sources and preprocessing steps

### **2. Python Environment**

* **Always use local conda Python environment** â€“ Stick to conda for package management
* **For GPU work only**: Use `module load cuda/12.1` when CUDA is required
* **Consistent environment** â€“ Use the same Python environment across all development
* **Package management** â€“ Use `conda install` or `pip install` within conda environment

### **3. File Management**

* **Donâ€™t generate many new test files** â€“ Work with existing file structure
* **Revise existing files instead** â€“ Modify current files rather than creating many new ones
* **Maintain clean directory structure** â€“ Donâ€™t create unnecessary nested directories
* **Reuse existing frameworks** â€“ Build on current codebase rather than starting from scratch
* **Always keep only one Markdown file: `README.md`** â€“ Do not create additional `.md` files; consolidate all documentation in `README.md`
* **Do not use emojis in `README.md`** â€“ Avoid all emoji icons (e.g., ğŸš€, âœ…, âŒ), as they convey an **informal tone** inconsistent with academic or professional documentation

### **4. Pre-Submission Housekeeping**

* **Delete unnecessary files** before submitting jobs to cluster:

  * Temporary files (`.tmp`, `.cache`, `__pycache__/`)
  * Large intermediate results that can be regenerated
  * Old log files and debug outputs
  * Duplicate or backup files
* **Clean up results directories** â€“ Remove outdated experimental results
* **Push to GitHub** â€“ Always commit and push changes before cluster submission
* **Verify file sizes** â€“ Ensure no large unnecessary files are being submitted

### **5. Version Control Workflow**

```bash
# Before every cluster job submission:
git add .
git commit -m "Prepare for cluster job: [brief description]"
git push origin main

# Clean up unnecessary files
rm -rf __pycache__/ *.tmp *.cache
rm old_results_*.json
```

### **6. Code Development Standards**

* **Modify existing scripts** â€“ Update current files rather than creating new ones
* **Use existing models and frameworks** â€“ Build on established codebase
* **Maintain backward compatibility** â€“ Donâ€™t break existing functionality
* **Follow established patterns** â€“ Use existing code style and structure

### **7. Academic Integrity**

* **No result fabrication** â€“ All results must come from actual experiments
* **No data manipulation** â€“ Use datasets as provided from legitimate sources
* **Proper attribution** â€“ Credit all methods, datasets, and prior work
* **Transparent methodology** â€“ Document all procedures clearly

### **8. Cluster Job Management**

* **Resource efficiency** â€“ Request appropriate resources, not excessive
* **Clean workspace** â€“ Remove unnecessary files before job submission
* **Version control** â€“ Always push code to GitHub before submitting
* **Monitor job status** â€“ Check job progress and handle failures appropriately
* **Do not exit the current session** â€“ You must remain logged in and actively monitor the job after submission.
  If an error occurs (e.g., out-of-memory, module failure, timeout), you must immediately:

  * Diagnose the problem
  * Fix the issue in the implementation server
  * Push changes to GitHub
  * Pull and resubmit the job on `dtuhpc`
  * Continue monitoring until the experiment completes successfully with **satisfactory final results**
  * **Exiting the session before reaching this stage is strictly prohibited**

### **9. Development Workflow**

1. **Modify existing files** instead of creating new ones
2. **Test locally** with conda Python environment
3. **Clean up workspace** â€“ Delete unnecessary files
4. **Commit and push** to GitHub
5. **Submit job** to cluster
6. **Monitor results** and iterate

---

**Core Principles**:

* Use real data to avoid academic misconduct
* Use local conda Python environment
* For GPU: `module load cuda/12.1`
* Revise existing files, donâ€™t create many new ones
* Always clean up and push to GitHub before cluster submission
* **Only maintain one documentation file: `README.md`**
* **Avoid emojis in documentation** â€“ use formal language only
* **Always monitor submitted jobsâ€”do not exit until results are satisfactory**